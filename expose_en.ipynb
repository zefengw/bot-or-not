{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "e56b0c68",
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib, bot_detector\n",
        "importlib.reload(bot_detector)\n",
        "from bot_detector import train_model, validate_on_dataset, generate_submission\n",
        "\n",
        "model, wv, cv, feats, threshold = train_model(data_dir=\"files\", lang=\"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "86fe25aa",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading EN datasets from files/...\n",
            "  Loaded dataset 30 (en): 275 users, 7528 posts, 66 bots\n",
            "  Loaded dataset 32 (en): 271 users, 8237 posts, 63 bots\n",
            "  Combined: 546 users, 15765 posts, 129 bots\n",
            "\n",
            "Extracting features (this may take a minute for sentiment analysis)...\n",
            "  Feature matrix: 546 users x 175 features\n",
            "  Label distribution: {0: 417, 1: 129}\n",
            "\n",
            "============================================================\n",
            "EVALUATION ON HELD-OUT TEST SET (EN)\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.91      1.00      0.95        84\n",
            "         Bot       1.00      0.69      0.82        26\n",
            "\n",
            "    accuracy                           0.93       110\n",
            "   macro avg       0.96      0.85      0.89       110\n",
            "weighted avg       0.93      0.93      0.92       110\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[84  0]\n",
            " [ 8 18]]\n",
            "\n",
            "Competition score (threshold=0.5): 64\n",
            "  TP=18 (+72), FN=8 (-8), FP=0 (0)\n",
            "\n",
            "Threshold sweep (competition score):\n",
            "  Thresh  Score   TP   FN   FP\n",
            "  ------  -----  ---  ---  ---\n",
            "    0.10     31   25    1   34\n",
            "    0.15     63   25    1   18\n",
            "    0.20     70   24    2   12\n",
            "    0.25     75   23    3    7\n",
            "    0.30     81   23    3    4\n",
            "    0.35     83   23    3    3\n",
            "    0.40     84   22    4    0 <-- best\n",
            "    0.45     74   20    6    0\n",
            "    0.50     64   18    8    0\n",
            "    0.55     64   18    8    0\n",
            "    0.60     44   14   12    0\n",
            "    0.65     39   13   13    0\n",
            "    0.70     29   11   15    0\n",
            "    0.75     24   10   16    0\n",
            "    0.80     19    9   17    0\n",
            "    0.85     19    9   17    0\n",
            "    0.90     -1    5   21    0\n",
            "\n",
            "Optimal threshold: 0.40 (score=84)\n",
            "\n",
            "Top 25 most important features:\n",
            "--------------------------------------------------\n",
            "   1. avg_hashtags                   0.0537\n",
            "   2. avg_question                   0.0465\n",
            "   3. avg_exclamation                0.0353\n",
            "   4. tfidf_word_37                  0.0345\n",
            "   5. tfidf_char_3                   0.0260\n",
            "   6. tfidf_char_15                  0.0256\n",
            "   7. std_time_diff                  0.0218\n",
            "   8. tfidf_char_0                   0.0201\n",
            "   9. tfidf_char_25                  0.0194\n",
            "  10. tfidf_word_86                  0.0189\n",
            "  11. tfidf_char_16                  0.0186\n",
            "  12. tfidf_word_53                  0.0174\n",
            "  13. tfidf_word_36                  0.0173\n",
            "  14. avg_time_diff                  0.0160\n",
            "  15. tfidf_char_19                  0.0152\n",
            "  16. tfidf_word_10                  0.0147\n",
            "  17. tfidf_word_56                  0.0145\n",
            "  18. avg_tweet_length               0.0121\n",
            "  19. tfidf_word_40                  0.0120\n",
            "  20. tfidf_char_2                   0.0113\n",
            "  21. tweet_count                    0.0103\n",
            "  22. min_time_diff                  0.0101\n",
            "  23. avg_emoji                      0.0096\n",
            "  24. tfidf_char_1                   0.0095\n",
            "  25. tfidf_char_29                  0.0095\n",
            "\n",
            "Retraining on full dataset for final model...\n"
          ]
        }
      ],
      "source": [
        "validate_on_dataset(model, wv, cv, \"files/dataset.posts&users.30.json\", \"files/dataset.bots.30.txt\", \"en\", threshold)\n",
        "validate_on_dataset(model, wv, cv, \"files/dataset.posts&users.32.json\", \"files/dataset.bots.32.txt\", \"en\", threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "268ee90a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VALIDATION ON PRACTICE DATASETS\n",
            "============================================================\n",
            "Validation on: dataset.posts&users.30.json\n",
            "  Users: 275 (66 bots, 209 humans)\n",
            "  Threshold: 0.40\n",
            "  Flagged as bot: 66\n",
            "  TP=66, FN=0, FP=0\n",
            "  Competition score: 264\n",
            "    (+4 x 66 = +264, -1 x 0 = 0, -2 x 0 = 0)\n",
            "\n",
            "Validation on: dataset.posts&users.32.json\n",
            "  Users: 271 (63 bots, 208 humans)\n",
            "  Threshold: 0.40\n",
            "  Flagged as bot: 63\n",
            "  TP=63, FN=0, FP=0\n",
            "  Competition score: 252\n",
            "    (+4 x 63 = +252, -1 x 0 = 0, -2 x 0 = 0)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(252, 63, 0, 0)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EVAL_PATH = \"EVAL_EN.json\"  # swap this for the real eval file\n",
        "generate_submission(model, wv, cv, EVAL_PATH, \"Chud\", \"en\", threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b722b223",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file created: Winners.detections.en.txt\n",
            "  63 users flagged as bots out of 271 total\n",
            "  Threshold used: 0.40\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8      76fe9797-fae4-4ebc-9631-459c0abe5b3a\n",
              "18     4186cb2d-4b34-41d1-af54-be1b0b470de5\n",
              "31     56a899a1-9400-409e-a044-4c9fd7e6ad39\n",
              "33     db2b8b01-e3f9-4ea4-a5d2-9ea4fbe542a8\n",
              "38     287eb099-7874-4aea-8371-1b16e2b542ad\n",
              "                       ...                 \n",
              "266    8e229365-e29a-4321-b70a-401c14b12139\n",
              "267    8c5f8a42-43aa-4421-8bd8-435fdb3f16f8\n",
              "268    653f27c6-1001-45f8-8ddb-6d610bfc4740\n",
              "269    dcf22af4-2648-458a-9f20-da15f2170069\n",
              "270    63518446-4f83-46ab-a436-305ca03fa61c\n",
              "Name: id, Length: 63, dtype: object"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
