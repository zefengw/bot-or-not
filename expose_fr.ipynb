{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c21875c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib, bot_detector\n",
        "importlib.reload(bot_detector)\n",
        "from bot_detector import train_model, validate_on_dataset, generate_submission\n",
        "\n",
        "model, wv, cv, feats, threshold = train_model(data_dir=\"files\", lang=\"fr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "14e710b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading FR datasets from files/...\n",
            "  Loaded dataset 31 (fr): 171 users, 4643 posts, 27 bots\n",
            "  Loaded dataset 33 (fr): 172 users, 4361 posts, 28 bots\n",
            "  Combined: 343 users, 9004 posts, 55 bots\n",
            "\n",
            "Extracting features (this may take a minute for sentiment analysis)...\n",
            "  Feature matrix: 343 users x 175 features\n",
            "  Label distribution: {0: 288, 1: 55}\n",
            "\n",
            "============================================================\n",
            "EVALUATION ON HELD-OUT TEST SET (FR)\n",
            "============================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.92      1.00      0.96        58\n",
            "         Bot       1.00      0.55      0.71        11\n",
            "\n",
            "    accuracy                           0.93        69\n",
            "   macro avg       0.96      0.77      0.83        69\n",
            "weighted avg       0.93      0.93      0.92        69\n",
            "\n",
            "Confusion matrix (rows=actual, cols=predicted):\n",
            "[[58  0]\n",
            " [ 5  6]]\n",
            "\n",
            "Competition score (threshold=0.5): 19\n",
            "  TP=6 (+24), FN=5 (-5), FP=0 (0)\n",
            "\n",
            "Threshold sweep (competition score):\n",
            "  Thresh  Score   TP   FN   FP\n",
            "  ------  -----  ---  ---  ---\n",
            "    0.10      2   11    0   21\n",
            "    0.15     24   11    0   10\n",
            "    0.20     22    9    2    6\n",
            "    0.25     24    9    2    5\n",
            "    0.30     28    9    2    3 <-- best\n",
            "    0.35     25    8    3    2\n",
            "    0.40     27    8    3    1\n",
            "    0.45     19    6    5    0\n",
            "    0.50     19    6    5    0\n",
            "    0.55     19    6    5    0\n",
            "    0.60     14    5    6    0\n",
            "    0.65      4    3    8    0\n",
            "    0.70     -1    2    9    0\n",
            "    0.75     -6    1   10    0\n",
            "    0.80     -6    1   10    0\n",
            "    0.85    -11    0   11    0\n",
            "    0.90    -11    0   11    0\n",
            "\n",
            "Optimal threshold: 0.30 (score=28)\n",
            "\n",
            "Top 25 most important features:\n",
            "--------------------------------------------------\n",
            "   1. avg_exclamation                0.0710\n",
            "   2. avg_hashtags                   0.0615\n",
            "   3. avg_question                   0.0300\n",
            "   4. tfidf_word_69                  0.0241\n",
            "   5. tfidf_word_92                  0.0231\n",
            "   6. tfidf_word_79                  0.0217\n",
            "   7. std_time_diff                  0.0203\n",
            "   8. tfidf_word_35                  0.0198\n",
            "   9. tfidf_char_29                  0.0193\n",
            "  10. tfidf_word_65                  0.0192\n",
            "  11. avg_upper_ratio                0.0164\n",
            "  12. tfidf_word_34                  0.0160\n",
            "  13. avg_emoji                      0.0155\n",
            "  14. tfidf_char_19                  0.0141\n",
            "  15. tfidf_word_68                  0.0125\n",
            "  16. tfidf_word_38                  0.0108\n",
            "  17. tfidf_word_25                  0.0106\n",
            "  18. tfidf_word_7                   0.0106\n",
            "  19. tfidf_char_18                  0.0105\n",
            "  20. tfidf_char_20                  0.0100\n",
            "  21. tfidf_char_25                  0.0099\n",
            "  22. tfidf_word_74                  0.0098\n",
            "  23. tfidf_char_1                   0.0097\n",
            "  24. min_time_diff                  0.0096\n",
            "  25. tfidf_char_3                   0.0090\n",
            "\n",
            "Retraining on full dataset for final model...\n"
          ]
        }
      ],
      "source": [
        "validate_on_dataset(model, wv, cv, \"files/dataset.posts&users.31.json\", \"files/dataset.bots.31.txt\", \"fr\", threshold)\n",
        "validate_on_dataset(model, wv, cv, \"files/dataset.posts&users.33.json\", \"files/dataset.bots.33.txt\", \"fr\", threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9ebf030a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "VALIDATION ON PRACTICE DATASETS\n",
            "============================================================\n",
            "Validation on: dataset.posts&users.31.json\n",
            "  Users: 171 (27 bots, 144 humans)\n",
            "  Threshold: 0.30\n",
            "  Flagged as bot: 27\n",
            "  TP=27, FN=0, FP=0\n",
            "  Competition score: 108\n",
            "    (+4 x 27 = +108, -1 x 0 = 0, -2 x 0 = 0)\n",
            "\n",
            "Validation on: dataset.posts&users.33.json\n",
            "  Users: 172 (28 bots, 144 humans)\n",
            "  Threshold: 0.30\n",
            "  Flagged as bot: 28\n",
            "  TP=28, FN=0, FP=0\n",
            "  Competition score: 112\n",
            "    (+4 x 28 = +112, -1 x 0 = 0, -2 x 0 = 0)\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(112, 28, 0, 0)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EVAL_PATH = \"EVAL_FR.json\"  # swap this for the real eval file\n",
        "generate_submission(model, wv, cv, EVAL_PATH, \"Chud\", \"fr\", threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1d0fb12",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
